{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tweets(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        import pickle\n",
    "        e_tweets = pickle.load(f)\n",
    "    return e_tweets\n",
    "\n",
    "labels = load_tweets(path = \"data/Sentiment_Labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "def process_tweets(tweets, labels, k = 20000, ngrams = (1, 2)):\n",
    "    train, test, y_train, y_test = train_test_split(tweets, labels, train_size=0.8, test_size=0.2, random_state=42)\n",
    "    \n",
    "    vectorizer = CountVectorizer(ngram_range = ngrams, stop_words='english')\n",
    "    train_bow = vectorizer.fit_transform(train)\n",
    "    test_bow = vectorizer.transform(test)\n",
    "    \n",
    "    selector = SelectKBest(f_classif, k).fit(train_bow, y_train)\n",
    "    train_topK_bow = selector.transform(train_bow).astype('float32')\n",
    "    test_topK_bow = selector.transform(test_bow).astype('float32')\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range = ngrams, stop_words='english')\n",
    "    train_tfidf = tfidf_vectorizer.fit_transform(train)\n",
    "    test_tfidf = tfidf_vectorizer.transform(test)\n",
    "    \n",
    "    selector_tfidf = SelectKBest(f_classif, k).fit(train_tfidf, y_train)\n",
    "    train_topK_tfidf = selector_tfidf.transform(train_tfidf).astype('float32')\n",
    "    test_topK_tfidf = selector.transform(test_tfidf).astype('float32')\n",
    "    \n",
    "    data = {}\n",
    "    data['bow'] = train_bow, test_bow, train_topK_bow, test_topK_bow\n",
    "    data['tfidf'] = train_tfidf, test_tfidf, train_topK_tfidf, test_topK_tfidf\n",
    "    data['labels'] = y_train, y_test\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets = load_tweets(path = \"data/clean_text.pkl\")\n",
    "clean_data =  process_tweets(clean_tweets, labels)\n",
    "y_train, y_test = clean_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Train Features shape: (34753, 178008), BoW Test Features shape: (8689, 178008) \n",
      "TF-IDF Train Features shape: (34753, 178008), TF-IDF Test Features shape: (8689, 178008) \n"
     ]
    }
   ],
   "source": [
    "train_bow, test_bow, train_topK_bow, test_topK_bow = clean_data['bow']\n",
    "train_tfidf, test_tfidf, train_topK_tfidf, test_topK_tfidf = clean_data['tfidf']\n",
    "\n",
    "print(f\"BoW Train Features shape: {train_bow.shape}, BoW Test Features shape: {test_bow.shape} \" )\n",
    "print(f\"TF-IDF Train Features shape: {train_tfidf.shape}, TF-IDF Test Features shape: {test_tfidf.shape} \" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    " \n",
    "def fit_and_metrics(classifier, train, test):\n",
    "    clf = classifier.fit(train, y_train)\n",
    "    y_predicted = clf.predict(test)\n",
    "    \n",
    "    \n",
    "    precision = precision_score(y_test, y_predicted, pos_label=None,\n",
    "                                    average='weighted')             \n",
    "    recall = recall_score(y_test, y_predicted, pos_label=None,\n",
    "                              average='weighted')\n",
    "    f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(multi_class='multinomial', max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Model: accuracy = 0.844, precision = 0.846, recall = 0.844, f1 = 0.843\n",
      "Top-K BoW: accuracy = 0.852, precision = 0.851, recall = 0.852, f1 = 0.851\n"
     ]
    }
   ],
   "source": [
    "accuracy_bow_lr, precision_bow_lr, recall_bow_lr, f1_bow_lr = fit_and_metrics(lr, train_bow, test_bow)\n",
    "\n",
    "accuracy_k_bow_lr, precision_k_bow_lr, recall_k_bow_lr, f1_k_bow_lr = fit_and_metrics(lr, train_topK_bow,\n",
    "                                                                                      test_topK_bow)\n",
    "print(\"BoW Model: accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_bow_lr, \n",
    "                                                                                  precision_bow_lr,\n",
    "                                                                                  recall_bow_lr, \n",
    "                                                                                  f1_bow_lr))\n",
    "\n",
    "print(\"Top-K BoW: accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_k_bow_lr, \n",
    "                                                                                  precision_k_bow_lr,\n",
    "                                                                                  recall_k_bow_lr, \n",
    "                                                                                  f1_k_bow_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Model: accuracy = 0.813, precision = 0.810, recall = 0.813, f1 = 0.807\n",
      "Top-K TF-IDF: accuracy = 0.798, precision = 0.795, recall = 0.798, f1 = 0.789\n"
     ]
    }
   ],
   "source": [
    "accuracy_tfidf_lr, precision_tfidf_lr, recall_tfidf_lr, f1_tfidf_lr = metrics(lr, train_tfidf, test_tfidf)\n",
    "\n",
    "accuracy_k_tfidf_lr, precision_k_tfidf_lr, recall_k_tfidf_lr, f1_k_tfidf_lr = fit_and_metrics(lr, train_topK_tfidf,\n",
    "                                                                                      test_topK_tfidf)\n",
    "\n",
    "print(\"TF-IDF Model: accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_tfidf_lr, \n",
    "                                                                                  precision_tfidf_lr,\n",
    "                                                                                  recall_tfidf_lr, \n",
    "                                                                                  f1_tfidf_lr))\n",
    "\n",
    "print(\"Top-K TF-IDF: accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_k_tfidf_lr, \n",
    "                                                                                  precision_k_tfidf_lr,\n",
    "                                                                                  recall_k_tfidf_lr, \n",
    "                                                                                  f1_k_tfidf_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "svm = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Model: accuracy = 0.847, precision = 0.851, recall = 0.847, f1 = 0.847\n",
      "Top-K BoW: accuracy = 0.863, precision = 0.864, recall = 0.863, f1 = 0.863\n"
     ]
    }
   ],
   "source": [
    "accuracy_bow_svm, precision_bow_svm, recall_bow_svm, f1_bow_svm = fit_and_metrics(svm, train_bow, test_bow)\n",
    "\n",
    "accuracy_k_bow_svm, precision_k_bow_svm, recall_k_bow_svm, f1_k_bow_svm = fit_and_metrics(svm, train_topK_bow,\n",
    "                                                                                      test_topK_bow)\n",
    "\n",
    "print(\"BoW Model: accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_bow_svm, \n",
    "                                                                                  precision_bow_svm, \n",
    "                                                                                  recall_bow_svm, \n",
    "                                                                                  f1_bow_svm))\n",
    "\n",
    "print(\"Top-K BoW: accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_k_bow_svm, \n",
    "                                                                                  precision_k_bow_svm,\n",
    "                                                                                  recall_k_bow_svm, \n",
    "                                                                                  f1_k_bow_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Model: accuracy = 0.786, precision = 0.787, recall = 0.786, f1 = 0.770\n",
      "Top-K TF-IDF: accuracy = 0.778, precision = 0.782, recall = 0.778, f1 = 0.758\n"
     ]
    }
   ],
   "source": [
    "accuracy_tfidf_svm, precision_tfidf_svm, recall_tfidf_svm, f1_tfidf_svm = fit_and_metrics(svm, train_tfidf, test_tfidf)\n",
    "\n",
    "accuracy_k_tfidf_svm, precision_k_tfidf_svm, recall_k_tfidf_svm, f1_k_tfidf_svm = fit_and_metrics(svm,train_topK_tfidf,\n",
    "                                                                                                  test_topK_tfidf)\n",
    "print(\"TF-IDF Model: accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_tfidf_svm, \n",
    "                                                                                     precision_tfidf_svm, \n",
    "                                                                                     recall_tfidf_svm, \n",
    "                                                                                     f1_tfidf_svm))\n",
    "print(\"Top-K TF-IDF: accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_k_tfidf_svm, \n",
    "                                                                                  precision_k_tfidf_svm,\n",
    "                                                                                  recall_k_tfidf_svm, \n",
    "                                                                                  f1_k_tfidf_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Model: accuracy = 0.810, precision = 0.817, recall = 0.810, f1 = 0.809\n",
      "Top-K BoW: accuracy = 0.807, precision = 0.806, recall = 0.807, f1 = 0.803\n"
     ]
    }
   ],
   "source": [
    "accuracy_bow_rf, precision_bow_rf, recall_bow_rf, f1_bow_rf = fit_and_metrics(rf, train_bow, test_bow)\n",
    "\n",
    "accuracy_k_bow_rf, precision_k_bow_rf, recall_k_bow_rf, f1_k_bow_rf = fit_and_metrics(rf, train_topK_bow,\n",
    "                                                                                      test_topK_bow)\n",
    "\n",
    "print(\"BoW Model: accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_bow_rf, \n",
    "                                                                                  precision_bow_rf, \n",
    "                                                                                  recall_bow_rf, \n",
    "                                                                                  f1_bow_rf))\n",
    "\n",
    "print(\"Top-K BoW: accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_k_bow_rf, \n",
    "                                                                                  precision_k_bow_rf,\n",
    "                                                                                  recall_k_bow_rf, \n",
    "                                                                                  f1_k_bow_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Model: accuracy = 0.806, precision = 0.811, recall = 0.806, f1 = 0.804\n",
      "Top-K TF-IDF: accuracy = 0.242, precision = 0.415, recall = 0.242, f1 = 0.176\n"
     ]
    }
   ],
   "source": [
    "accuracy_tfidf_rf, precision_tfidf_rf, recall_tfidf_rf, f1_tfidf_rf = fit_and_metrics(rf, train_tfidf, test_tfidf)\n",
    "\n",
    "accuracy_k_tfidf_rf, precision_k_tfidf_rf, recall_k_tfidf_rf, f1_k_tfidf_rf = fit_and_metrics(rf, train_topK_tfidf,\n",
    "                                                                                      test_topK_tfidf)\n",
    "\n",
    "print(\"TF-IDF Model: accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_tfidf_rf, \n",
    "                                                                                     precision_tfidf_rf, \n",
    "                                                                                     recall_tfidf_rf, \n",
    "                                                                                     f1_tfidf_rf))\n",
    "\n",
    "print(\"Top-K TF-IDF: accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_k_tfidf_rf, \n",
    "                                                                                  precision_k_tfidf_rf,\n",
    "                                                                                  recall_k_tfidf_rf, \n",
    "                                                                                  f1_k_tfidf_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifiers = [\n",
    "    LogisticRegression(multi_class='multinomial', max_iter=500),\n",
    "    SGDClassifier(),\n",
    "    RandomForestClassifier()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemmed Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_tweets = load_tweets(path = \"data/stemmed_text.pkl\")\n",
    "stem_data =  process_tweets(stem_tweets, labels)\n",
    "stem_train, stem_test = stem_data['bow'][0], stem_data['bow'][1]\n",
    "y_train, y_test = stem_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression is 0.8346184831396017\n",
      "Accuracy of SGDClassifier is 0.8362297157325354\n",
      "Accuracy of RandomForestClassifier is 0.8037748877891587\n"
     ]
    }
   ],
   "source": [
    "for clf in Classifiers:\n",
    "    fit = clf.fit(stem_train, y_train)\n",
    "    pred = fit.predict(stem_test) \n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    print(\"Accuracy of \" + clf.__class__.__name__ + \" is \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatized Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem_tweets = load_tweets(path = \"data/lemmatized_text.pkl\")\n",
    "lem_data =  process_tweets(lem_tweets, labels)\n",
    "lem_train, lem_test = lem_data['bow'][0], lem_data['bow'][1]\n",
    "y_train, y_test = lem_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression is 0.8394521809184026\n",
      "Accuracy of SGDClassifier is 0.843595350443089\n",
      "Accuracy of RandomForestClassifier is 0.8007825986879963\n"
     ]
    }
   ],
   "source": [
    "for clf in Classifiers:\n",
    "    fit = clf.fit(lem_train, y_train)\n",
    "    pred = fit.predict(lem_test) \n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    print(\"Accuracy of \" + clf.__class__.__name__ + \" is \" + str(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
